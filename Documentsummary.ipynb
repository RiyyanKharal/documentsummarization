{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a180801-9bcf-41eb-8c75-2a5ea005b40e",
   "metadata": {},
   "source": [
    "### Project Title: Document Summarization using Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8a7f8d-83fe-486c-a4b7-ea32af23bfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\riyya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loading dataset...\n",
      "\n",
      "================= Article 1 =================\n",
      "üß© Chunking...\n",
      "‚è±Ô∏è Chunking took: 0.00s\n",
      "üîé Embedding...\n",
      "‚è±Ô∏è Embedding took: 0.25s\n",
      "üì¶ Building vector index...\n",
      "‚è±Ô∏è Indexing took: 0.00s\n",
      "üì• Retrieving relevant chunks...\n",
      "‚è±Ô∏è Retrieval took: 0.03s\n",
      "\n",
      "üîç Top Retrieved Chunks with Similarity Scores:\n",
      "\n",
      "--- Chunk 1 | Similarity: 0.0943 ---\n",
      "office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecu...\n",
      "\n",
      "--- Chunk 2 | Similarity: -0.0110 ---\n",
      "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the cou...\n",
      "\n",
      "--- Chunk 3 | Similarity: 0.0943 ---\n",
      "office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecu...\n",
      "\n",
      "--- Chunk 4 | Similarity: 0.0943 ---\n",
      "office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecu...\n",
      "\n",
      "--- Chunk 5 | Similarity: 0.0943 ---\n",
      "office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecu...\n",
      "\n",
      "üìù Generating summary...\n",
      "‚è±Ô∏è Summarization took: 20.08s\n",
      "\n",
      "‚úÖ Summary:\n",
      "Palestinian Authority officially becomes 123rd member of the International Criminal Court. The formal accession was marked with a ceremony at The Hague, in the Netherlands. The move gives the court jurisdiction over alleged crimes in Palestinian territories. The war between Israel and Hamas militants in Gaza last summer left more than 2,000 dead.\n",
      "\n",
      "üìä Stats:\n",
      "- Approx. input tokens: 627\n",
      "- Approx. summary tokens: 53\n",
      "\n",
      "================= Article 2 =================\n",
      "üß© Chunking...\n",
      "‚è±Ô∏è Chunking took: 0.00s\n",
      "üîé Embedding...\n",
      "‚è±Ô∏è Embedding took: 0.10s\n",
      "üì¶ Building vector index...\n",
      "‚è±Ô∏è Indexing took: 0.00s\n",
      "üì• Retrieving relevant chunks...\n",
      "‚è±Ô∏è Retrieval took: 0.03s\n",
      "\n",
      "üîç Top Retrieved Chunks with Similarity Scores:\n",
      "\n",
      "--- Chunk 1 | Similarity: 0.0342 ---\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State Univ...\n",
      "\n",
      "--- Chunk 2 | Similarity: 0.0342 ---\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State Univ...\n",
      "\n",
      "--- Chunk 3 | Similarity: 0.0342 ---\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State Univ...\n",
      "\n",
      "--- Chunk 4 | Similarity: 0.0342 ---\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State Univ...\n",
      "\n",
      "--- Chunk 5 | Similarity: 0.0342 ---\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State Univ...\n",
      "\n",
      "üìù Generating summary...\n",
      "‚è±Ô∏è Summarization took: 22.98s\n",
      "\n",
      "‚úÖ Summary:\n",
      "Theia is only one year old but the dog's brush with death did not leave her unscathed. She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity. She was taken in by Moses Lake, Washington, resident Sara Mellado. \"She's a true miracle dog and she deserves a good life,\" Mellado says.\n",
      "\n",
      "üìä Stats:\n",
      "- Approx. input tokens: 700\n",
      "- Approx. summary tokens: 53\n",
      "\n",
      "================= Article 3 =================\n",
      "üß© Chunking...\n",
      "‚è±Ô∏è Chunking took: 0.00s\n",
      "üîé Embedding...\n",
      "‚è±Ô∏è Embedding took: 0.21s\n",
      "üì¶ Building vector index...\n",
      "‚è±Ô∏è Indexing took: 0.00s\n",
      "üì• Retrieving relevant chunks...\n",
      "‚è±Ô∏è Retrieval took: 0.02s\n",
      "\n",
      "üîç Top Retrieved Chunks with Similarity Scores:\n",
      "\n",
      "--- Chunk 1 | Similarity: 0.0472 ---\n",
      "controlling the Alavi Foundation, a charitable organization. The U.S. Justice Department said the organization was secretly run on behalf of the Iranian government to launder money and get around U.S. sanctions. But last year, a settlement in the case, under which the foundation agreed to give a 36-...\n",
      "\n",
      "--- Chunk 2 | Similarity: 0.0108 ---\n",
      "(CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of State John Kerry's opposite number in securing a breakthrough in nuclear discussions that could lead to...\n",
      "\n",
      "--- Chunk 3 | Similarity: 0.0472 ---\n",
      "controlling the Alavi Foundation, a charitable organization. The U.S. Justice Department said the organization was secretly run on behalf of the Iranian government to launder money and get around U.S. sanctions. But last year, a settlement in the case, under which the foundation agreed to give a 36-...\n",
      "\n",
      "--- Chunk 4 | Similarity: 0.0472 ---\n",
      "controlling the Alavi Foundation, a charitable organization. The U.S. Justice Department said the organization was secretly run on behalf of the Iranian government to launder money and get around U.S. sanctions. But last year, a settlement in the case, under which the foundation agreed to give a 36-...\n",
      "\n",
      "--- Chunk 5 | Similarity: 0.0472 ---\n",
      "controlling the Alavi Foundation, a charitable organization. The U.S. Justice Department said the organization was secretly run on behalf of the Iranian government to launder money and get around U.S. sanctions. But last year, a settlement in the case, under which the foundation agreed to give a 36-...\n",
      "\n",
      "üìù Generating summary...\n",
      "‚è±Ô∏è Summarization took: 20.20s\n",
      "\n",
      "‚úÖ Summary:\n",
      "Mohammad Javad Zarif was among the students who took over the Iranian Consulate in San Francisco. He has been U.S. Secretary of State John Kerry's opposite number in securing a breakthrough in nuclear discussions. He received a hero's welcome as he arrived in Iran on a sunny Friday morning.\n",
      "\n",
      "üìä Stats:\n",
      "- Approx. input tokens: 682\n",
      "- Approx. summary tokens: 49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download punkt tokenizer (for word_tokenize)\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load summarization model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Load sentence embedding model\n",
    "EMBED_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# === Constants ===\n",
    "TOP_K = 5               # Chunks to retrieve\n",
    "CHUNK_SIZE = 500        # Words per chunk\n",
    "MAX_SUMMARY_CHARS = 4000  # Max characters for LLM context\n",
    "\n",
    "# === Utility Functions ===\n",
    "def clean_text(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def estimate_tokens(text):\n",
    "    try:\n",
    "        return len(word_tokenize(text))\n",
    "    except:\n",
    "        return len(text.split())\n",
    "\n",
    "# === Step 1: Chunking ===\n",
    "def chunk_text(text, chunk_size=CHUNK_SIZE):\n",
    "    words = text.split()\n",
    "    chunks = [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# === Step 2: Embedding ===\n",
    "def embed_chunks(chunks):\n",
    "    return EMBED_MODEL.encode(chunks, convert_to_numpy=True)\n",
    "\n",
    "# === Step 3: FAISS Index ===\n",
    "def build_faiss_index(embeddings):\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# === Step 4: Retrieval ===\n",
    "def retrieve_chunks(query, chunks, embeddings, index, top_k=TOP_K):\n",
    "    query_embed = EMBED_MODEL.encode([query], convert_to_numpy=True)\n",
    "    D, I = index.search(query_embed, top_k)\n",
    "    similarities = cosine_similarity(query_embed, embeddings)[0]\n",
    "    return [(chunks[i], similarities[i]) for i in I[0]], query_embed\n",
    "\n",
    "# === Step 5: Summarization ===\n",
    "def summarize_with_huggingface(context_chunks, max_char_len=MAX_SUMMARY_CHARS):\n",
    "    combined = clean_text(\" \".join(context_chunks))\n",
    "    if len(combined) > max_char_len:\n",
    "        combined = combined[:max_char_len]\n",
    "    summary = summarizer(combined, max_length=300, min_length=60, do_sample=False)[0]['summary_text']\n",
    "    return summary, combined\n",
    "\n",
    "# === Step 6: Full Pipeline per Article ===\n",
    "def summarize_article(article_text):\n",
    "    print(\"üß© Chunking...\")\n",
    "    start = time.time()\n",
    "    chunks = chunk_text(article_text)\n",
    "    print(f\"‚è±Ô∏è Chunking took: {time.time() - start:.2f}s\")\n",
    "\n",
    "    print(\"üîé Embedding...\")\n",
    "    start = time.time()\n",
    "    embeddings = embed_chunks(chunks)\n",
    "    print(f\"‚è±Ô∏è Embedding took: {time.time() - start:.2f}s\")\n",
    "\n",
    "    print(\"üì¶ Building vector index...\")\n",
    "    start = time.time()\n",
    "    index = build_faiss_index(np.array(embeddings))\n",
    "    print(f\"‚è±Ô∏è Indexing took: {time.time() - start:.2f}s\")\n",
    "\n",
    "    print(\"üì• Retrieving relevant chunks...\")\n",
    "    start = time.time()\n",
    "    retrieved, _ = retrieve_chunks(\"Summarize this document\", chunks, embeddings, index)\n",
    "    print(f\"‚è±Ô∏è Retrieval took: {time.time() - start:.2f}s\")\n",
    "\n",
    "    print(\"\\nüîç Top Retrieved Chunks with Similarity Scores:\")\n",
    "    context_chunks = []\n",
    "    for i, (chunk, score) in enumerate(retrieved):\n",
    "        print(f\"\\n--- Chunk {i+1} | Similarity: {score:.4f} ---\")\n",
    "        print(chunk[:300] + (\"...\" if len(chunk) > 300 else \"\"))\n",
    "        context_chunks.append(chunk)\n",
    "\n",
    "    print(\"\\nüìù Generating summary...\")\n",
    "    start = time.time()\n",
    "    summary, input_text = summarize_with_huggingface(context_chunks)\n",
    "    print(f\"‚è±Ô∏è Summarization took: {time.time() - start:.2f}s\")\n",
    "\n",
    "    print(\"\\n‚úÖ Summary:\")\n",
    "    print(summary)\n",
    "\n",
    "    print(\"\\nüìä Stats:\")\n",
    "    print(f\"- Approx. input tokens: {estimate_tokens(input_text)}\")\n",
    "    print(f\"- Approx. summary tokens: {estimate_tokens(summary)}\")\n",
    "\n",
    "# === Main ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üìö Loading dataset...\")\n",
    "    ds = load_dataset(\"abisee/cnn_dailymail\", \"1.0.0\", split=\"test\")\n",
    "    articles = [sample['article'] for sample in ds.select(range(3))]\n",
    "\n",
    "    for idx, article in enumerate(articles):\n",
    "        print(f\"\\n================= Article {idx + 1} =================\")\n",
    "        summarize_article(article)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
